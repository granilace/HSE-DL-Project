{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.autograd as autograd\n",
    "import torch.nn as nn\n",
    "\n",
    "from torchvision import models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "#device = torch.device('cpu')\n",
    "BATCH_SIZE = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.vgg11(pretrained=True).to(device)\n",
    "model.eval();\n",
    "\n",
    "for layer in model.parameters():\n",
    "    layer.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer = model.features[:6]\n",
    "\n",
    "img_batch = torch.randn(BATCH_SIZE, 3, 224, 224, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#v1 = 5 * torch.ones(img_batch_copy.shape[1:])\n",
    "v1 = torch.randn(150528, device=device)\n",
    "#v2 = torch.ones(output_batch.shape[1:], requires_grad=True)\n",
    "v2 = torch.randn(401408, requires_grad=True, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_v1 = v1.clone()\n",
    "new_v2 = v2.detach().clone().requires_grad_(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = img_batch.shape[0]\n",
    "img_batch_copy = img_batch.view(batch_size, -1).requires_grad_(True)\n",
    "\n",
    "if img_batch_copy.dim() == 2:\n",
    "    output_batch = layer(img_batch_copy.reshape(batch_size, 3, 224, 224)).reshape(batch_size, -1)\n",
    "    \n",
    "#v1 = 5 * torch.ones(img_batch_copy.shape[1:])\n",
    "#v2 = torch.ones(output_batch.shape[1:], requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "CPU times: user 58 s, sys: 18.5 s, total: 1min 16s\n",
      "Wall time: 12.9 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "prod = output_batch @ v2\n",
    "\n",
    "grad = []\n",
    "for i in range(BATCH_SIZE):\n",
    "    print(i)\n",
    "    grad.append(autograd.grad(prod[i], img_batch_copy, create_graph=True)[0][i])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 8.55 ms, sys: 1.09 ms, total: 9.64 ms\n",
      "Wall time: 2 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([0., 0., 0.,  ..., 0., 0., 0.])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "g = [grad[i] @ v1 for i in range(32)]\n",
    "v2.data.zero_();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3min 36s, sys: 45.4 s, total: 4min 21s\n",
      "Wall time: 44 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "common_mv = [autograd.grad(g[i], v2, retain_graph=True)[0] for i in range(32)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "cublas runtime error : an invalid numeric value was used as an argument at /opt/conda/conda-bld/pytorch_1565272279342/work/aten/src/THC/THCBlas.cu:120",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/NLP/lib/python3.6/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mgrad\u001b[0;34m(outputs, inputs, grad_outputs, retain_graph, create_graph, only_inputs, allow_unused)\u001b[0m\n\u001b[1;32m    147\u001b[0m     return Variable._execution_engine.run_backward(\n\u001b[1;32m    148\u001b[0m         \u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 149\u001b[0;31m         inputs, allow_unused)\n\u001b[0m\u001b[1;32m    150\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: cublas runtime error : an invalid numeric value was used as an argument at /opt/conda/conda-bld/pytorch_1565272279342/work/aten/src/THC/THCBlas.cu:120"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "new_prod = output_batch @ new_v2\n",
    "\n",
    "new_grad = autograd.grad(new_prod.sum(), img_batch_copy, create_graph=True)[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 10.4 ms, sys: 13.7 ms, total: 24.1 ms\n",
      "Wall time: 23.1 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "new_prod = output_batch @ new_v2\n",
    "\n",
    "new_new_grad = autograd.grad(\n",
    "    new_prod,\n",
    "    img_batch_copy,\n",
    "    grad_outputs=torch.ones_like(new_prod, device=device),\n",
    "    create_graph=True\n",
    ")[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0466, -1.1997, -5.1168,  ..., -0.2571, -1.9847, -3.0508],\n",
       "        [ 2.1679, -0.0437, -5.8366,  ...,  1.0069,  1.4890, -1.1506],\n",
       "        [ 8.5470, -1.6165, -3.5893,  ..., -2.0583,  1.3400,  0.3777],\n",
       "        ...,\n",
       "        [-0.4579, -6.0328, -4.5872,  ...,  3.1793,  1.0728, -0.0277],\n",
       "        [-1.0957, -0.2958, -1.4569,  ...,  1.9615, -1.5942,  1.6630],\n",
       "        [-3.0009,  2.6455,  2.0456,  ...,  2.0641, -0.2099, -0.0704]],\n",
       "       device='cuda:0', grad_fn=<AsStridedBackward>)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_new_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 301 µs, sys: 72 µs, total: 373 µs\n",
      "Wall time: 224 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "new_g = new_new_grad @ new_v1\n",
    "#new_v2.data.zero_();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.71 s, sys: 1.24 s, total: 3.96 s\n",
      "Wall time: 3.95 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "new_common_mv = [\n",
    "    autograd.grad(new_g[i], new_v2, retain_graph=True)[0]\n",
    "    for i in range(32)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 9.5443], device='cuda:0'),\n",
       " tensor([0., 0., 0.,  ..., 0., 0., 0.], device='cuda:0'),\n",
       " tensor([ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000, -5.2978],\n",
       "        device='cuda:0'),\n",
       " tensor([0., 0., 0.,  ..., 0., 0., 0.], device='cuda:0'),\n",
       " tensor([0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 8.1710], device='cuda:0')]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_common_mv[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor([  41.2515, -309.2067,   66.7329,  ...,   79.7467,    0.0000,\n",
      "        1347.6770], device='cuda:0'), tensor([  41.2515, -309.2067,   66.7329,  ...,   79.7467,    0.0000,\n",
      "        1347.6770], device='cuda:0'), tensor([  41.2515, -309.2067,   66.7329,  ...,   79.7467,    0.0000,\n",
      "        1347.6770], device='cuda:0'), tensor([  41.2515, -309.2067,   66.7329,  ...,   79.7467,    0.0000,\n",
      "        1347.6770], device='cuda:0'), tensor([  41.2515, -309.2067,   66.7329,  ...,   79.7467,    0.0000,\n",
      "        1347.6770], device='cuda:0'))\n",
      "16 torch.Size([401408])\n",
      "CPU times: user 455 ms, sys: 151 ms, total: 606 ms\n",
      "Wall time: 605 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "a = autograd.grad(\n",
    "    iter(new_g), [new_v2 for _ in range(16)],\n",
    "    iter(torch.ones(32, 32, device=device)),\n",
    "    retain_graph=True\n",
    ")\n",
    "print(a[:5])\n",
    "print(len(a), a[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_v2 = torch.tensor([1., 2., 1.], requires_grad=True, device=device)\n",
    "tmp = torch.tensor([[0., 1., 1.], [1., 0., 1.]], device=device)\n",
    "out_g = tmp @ in_v2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor([1., 1., 2.], device='cuda:0'), tensor([1., 1., 2.], device='cuda:0'))\n"
     ]
    }
   ],
   "source": [
    "a = autograd.grad(\n",
    "    out_g, [in_v2 for _ in range(2)],\n",
    "    torch.eye(2, device=device),\n",
    "    retain_graph=True\n",
    ")\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor([0., 1., 1.], device='cuda:0'), tensor([0., 1., 1.], device='cuda:0'))\n"
     ]
    }
   ],
   "source": [
    "a = autograd.grad(\n",
    "    out_g, [in_v2 for _ in range(2)],\n",
    "    [torch.tensor([1.0, 0.], device=device), torch.tensor([0., 1.], device=device)],\n",
    "    retain_graph=True\n",
    ")\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor([1., 2., 3.], device='cuda:0'), tensor([1., 2., 3.], device='cuda:0'))\n"
     ]
    }
   ],
   "source": [
    "a = autograd.grad(\n",
    "    iter(out_g), [in_v2 for _ in range(2)],\n",
    "    iter(torch.tensor([[1.0, 1.0], [1., 0.], [56.0, 12.0]], device=device)),\n",
    "    retain_graph=True\n",
    ")\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'tuple' object has no attribute 'shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'tuple' object has no attribute 'shape'"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "new_new_common_mv = autograd.grad(\n",
    "    new_g,\n",
    "    [new_v2 for _ in range(BATCH_SIZE)],\n",
    "    grad_outputs=torch.eye(32, device=device),\n",
    "    retain_graph=True\n",
    ")\n",
    "new_new_common_mv.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([  1.9591,   1.0481,  -4.4336,  ...,   0.0000,   0.0000, -31.6963],\n",
       "        device='cuda:0'),\n",
       " tensor([  1.9591,   1.0481,  -4.4336,  ...,   0.0000,   0.0000, -31.6963],\n",
       "        device='cuda:0'),\n",
       " tensor([  1.9591,   1.0481,  -4.4336,  ...,   0.0000,   0.0000, -31.6963],\n",
       "        device='cuda:0'),\n",
       " tensor([  1.9591,   1.0481,  -4.4336,  ...,   0.0000,   0.0000, -31.6963],\n",
       "        device='cuda:0'),\n",
       " tensor([  1.9591,   1.0481,  -4.4336,  ...,   0.0000,   0.0000, -31.6963],\n",
       "        device='cuda:0'),\n",
       " tensor([  1.9591,   1.0481,  -4.4336,  ...,   0.0000,   0.0000, -31.6963],\n",
       "        device='cuda:0'),\n",
       " tensor([  1.9591,   1.0481,  -4.4336,  ...,   0.0000,   0.0000, -31.6963],\n",
       "        device='cuda:0'),\n",
       " tensor([  1.9591,   1.0481,  -4.4336,  ...,   0.0000,   0.0000, -31.6963],\n",
       "        device='cuda:0'),\n",
       " tensor([  1.9591,   1.0481,  -4.4336,  ...,   0.0000,   0.0000, -31.6963],\n",
       "        device='cuda:0'),\n",
       " tensor([  1.9591,   1.0481,  -4.4336,  ...,   0.0000,   0.0000, -31.6963],\n",
       "        device='cuda:0'),\n",
       " tensor([  1.9591,   1.0481,  -4.4336,  ...,   0.0000,   0.0000, -31.6963],\n",
       "        device='cuda:0'),\n",
       " tensor([  1.9591,   1.0481,  -4.4336,  ...,   0.0000,   0.0000, -31.6963],\n",
       "        device='cuda:0'),\n",
       " tensor([  1.9591,   1.0481,  -4.4336,  ...,   0.0000,   0.0000, -31.6963],\n",
       "        device='cuda:0'),\n",
       " tensor([  1.9591,   1.0481,  -4.4336,  ...,   0.0000,   0.0000, -31.6963],\n",
       "        device='cuda:0'),\n",
       " tensor([  1.9591,   1.0481,  -4.4336,  ...,   0.0000,   0.0000, -31.6963],\n",
       "        device='cuda:0'),\n",
       " tensor([  1.9591,   1.0481,  -4.4336,  ...,   0.0000,   0.0000, -31.6963],\n",
       "        device='cuda:0'),\n",
       " tensor([  1.9591,   1.0481,  -4.4336,  ...,   0.0000,   0.0000, -31.6963],\n",
       "        device='cuda:0'),\n",
       " tensor([  1.9591,   1.0481,  -4.4336,  ...,   0.0000,   0.0000, -31.6963],\n",
       "        device='cuda:0'),\n",
       " tensor([  1.9591,   1.0481,  -4.4336,  ...,   0.0000,   0.0000, -31.6963],\n",
       "        device='cuda:0'),\n",
       " tensor([  1.9591,   1.0481,  -4.4336,  ...,   0.0000,   0.0000, -31.6963],\n",
       "        device='cuda:0'),\n",
       " tensor([  1.9591,   1.0481,  -4.4336,  ...,   0.0000,   0.0000, -31.6963],\n",
       "        device='cuda:0'),\n",
       " tensor([  1.9591,   1.0481,  -4.4336,  ...,   0.0000,   0.0000, -31.6963],\n",
       "        device='cuda:0'),\n",
       " tensor([  1.9591,   1.0481,  -4.4336,  ...,   0.0000,   0.0000, -31.6963],\n",
       "        device='cuda:0'),\n",
       " tensor([  1.9591,   1.0481,  -4.4336,  ...,   0.0000,   0.0000, -31.6963],\n",
       "        device='cuda:0'),\n",
       " tensor([  1.9591,   1.0481,  -4.4336,  ...,   0.0000,   0.0000, -31.6963],\n",
       "        device='cuda:0'),\n",
       " tensor([  1.9591,   1.0481,  -4.4336,  ...,   0.0000,   0.0000, -31.6963],\n",
       "        device='cuda:0'),\n",
       " tensor([  1.9591,   1.0481,  -4.4336,  ...,   0.0000,   0.0000, -31.6963],\n",
       "        device='cuda:0'),\n",
       " tensor([  1.9591,   1.0481,  -4.4336,  ...,   0.0000,   0.0000, -31.6963],\n",
       "        device='cuda:0'),\n",
       " tensor([  1.9591,   1.0481,  -4.4336,  ...,   0.0000,   0.0000, -31.6963],\n",
       "        device='cuda:0'),\n",
       " tensor([  1.9591,   1.0481,  -4.4336,  ...,   0.0000,   0.0000, -31.6963],\n",
       "        device='cuda:0'),\n",
       " tensor([  1.9591,   1.0481,  -4.4336,  ...,   0.0000,   0.0000, -31.6963],\n",
       "        device='cuda:0'),\n",
       " tensor([  1.9591,   1.0481,  -4.4336,  ...,   0.0000,   0.0000, -31.6963],\n",
       "        device='cuda:0'))"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_new_common_mv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "autograd.grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([401408])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_v2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "invalid gradient at index 0 - expected type torch.cuda.FloatTensor but got torch.FloatTensor",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-29-805bc9294adb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mimg_batch_copy\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mgrad_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mones\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m401408\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mones\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m401408\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mretain_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m )[0]\n",
      "\u001b[0;32m~/anaconda3/envs/NLP/lib/python3.6/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mgrad\u001b[0;34m(outputs, inputs, grad_outputs, retain_graph, create_graph, only_inputs, allow_unused)\u001b[0m\n\u001b[1;32m    147\u001b[0m     return Variable._execution_engine.run_backward(\n\u001b[1;32m    148\u001b[0m         \u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 149\u001b[0;31m         inputs, allow_unused)\n\u001b[0m\u001b[1;32m    150\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: invalid gradient at index 0 - expected type torch.cuda.FloatTensor but got torch.FloatTensor"
     ]
    }
   ],
   "source": [
    "lel = autograd.grad(\n",
    "    output_batch, \n",
    "    img_batch_copy,\n",
    "    grad_outputs=[torch.ones(32, 401408), torch.ones(32, 401408), v1], \n",
    "    retain_graph=True\n",
    ")[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "pupa = torch.stack(common_mv)\n",
    "lupa = torch.stack(new_common_mv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "140454705383896"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id(img_batch.contiguous())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "140454705383896"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id(img_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.autograd as autograd\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer = nn.Sequential(\n",
    "    nn.Linear(1000, 500),\n",
    "    nn.ReLU()\n",
    ")\n",
    "\n",
    "img_batch = torch.randn(32, 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#v1 = 5 * torch.ones(img_batch_copy.shape[1:])\n",
    "v1 = torch.randn(1000)\n",
    "#v2 = torch.ones(output_batch.shape[1:], requires_grad=True)\n",
    "v2 = torch.randn(500, requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.2546,  0.2825,  0.2804,  1.0867,  0.7721,  0.3622, -0.5979, -0.5619,\n",
       "        -0.8070,  0.4958,  0.0262, -0.4871, -1.2632,  1.1464,  0.0784,  0.2070,\n",
       "        -0.2882, -1.5814, -0.5747,  0.4433,  0.8672,  1.2101,  0.9946, -2.5411,\n",
       "         1.3365, -0.6848, -0.3588,  0.1659,  0.6818, -0.1192, -0.0901,  1.2334,\n",
       "         2.8858, -1.4674, -2.0275,  0.6004, -1.4563,  0.0986, -0.1476, -0.2667,\n",
       "        -0.3497, -0.6536, -0.5182,  0.8500, -0.1064, -1.7516, -0.4474,  0.0311,\n",
       "         0.7674,  1.1715, -0.5634,  0.3112,  0.7803, -0.2004,  1.1978, -0.4738,\n",
       "        -0.2542, -1.3166,  0.0118, -2.2514,  0.6150, -2.2872,  0.3073,  0.9277,\n",
       "        -0.4295, -1.8750,  0.6777,  0.4519,  1.1443,  1.0001,  0.8119, -0.3817,\n",
       "         0.0789, -0.9182, -1.6049, -0.4204,  0.4300, -0.0655,  0.2086, -0.0031,\n",
       "         0.0825,  0.1779,  0.9970,  0.0059,  0.6481,  0.5044, -0.6111, -2.1053,\n",
       "         1.3982, -1.0493, -0.4526, -0.9328, -0.9673, -0.6060, -2.0955, -0.5374,\n",
       "        -0.9446, -1.2989,  0.3348,  0.3178], grad_fn=<SliceBackward>)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v2[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_batch_copy = img_batch.clone().requires_grad_(True)\n",
    "\n",
    "output_batch = layer(img_batch_copy)\n",
    "    \n",
    "#v1 = 5 * torch.ones(img_batch_copy.shape[1:])\n",
    "#v2 = torch.ones(output_batch.shape[1:], requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.1110, 0.0000, 0.0000,  ..., 0.0000, 0.5476, 0.8789],\n",
       "        [0.6741, 0.0000, 0.0000,  ..., 0.0000, 0.4007, 0.0521],\n",
       "        [0.0000, 0.0000, 0.6442,  ..., 0.8388, 0.0000, 0.5958],\n",
       "        ...,\n",
       "        [0.8039, 0.1303, 0.0000,  ..., 0.0000, 0.4765, 0.0000],\n",
       "        [0.2398, 0.0037, 0.3700,  ..., 0.0402, 0.6447, 1.4258],\n",
       "        [0.0000, 0.6830, 0.0000,  ..., 0.4809, 0.0000, 0.7615]],\n",
       "       grad_fn=<ReluBackward0>)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "prod = output_batch @ v2\n",
    "\n",
    "grad = []\n",
    "for i in range(32):\n",
    "    grad.append(autograd.grad(prod[i], img_batch_copy, retain_graph=True, create_graph=True)[0][i])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 1.6601e-01, -3.6088e-01, -1.9948e-02,  4.3331e-01,  2.0584e-02,\n",
       "         3.7855e-02,  6.9233e-01,  3.2370e-01, -3.0797e-01, -1.9091e-01,\n",
       "         2.7293e-01, -1.1951e-01, -7.6927e-02, -9.8618e-02,  1.6786e-01,\n",
       "        -3.2780e-01, -3.7215e-01,  1.6748e-01,  2.7731e-01, -4.1819e-02,\n",
       "        -3.6323e-01, -2.1436e-01,  2.7398e-01,  4.4455e-01,  1.0986e-01,\n",
       "         2.9508e-02,  9.2924e-01,  3.1152e-01,  2.1843e-01,  7.6213e-02,\n",
       "        -1.3701e-01,  2.5774e-02,  6.8287e-02, -8.6855e-01,  2.8958e-01,\n",
       "        -1.8949e-01, -9.8556e-02,  2.9287e-01,  8.2704e-03,  3.2341e-01,\n",
       "        -1.8028e-01,  9.8288e-02,  1.2090e-01, -2.1645e-01, -5.2486e-02,\n",
       "        -2.3969e-02, -7.0296e-02, -9.8526e-02, -1.7235e-01,  4.3142e-01,\n",
       "         5.8110e-01,  5.0458e-01, -1.0733e-01,  1.6641e-01, -2.3055e-01,\n",
       "         3.9658e-01,  5.7112e-02, -4.1066e-01,  1.9311e-01, -1.7012e-01,\n",
       "         1.1305e-01, -4.5183e-01,  1.2717e-04, -6.3801e-02,  4.0950e-01,\n",
       "        -2.4851e-01, -1.0898e-01,  1.4688e-01,  3.0923e-01,  6.0435e-01,\n",
       "        -3.0507e-01, -6.7724e-02,  3.3812e-02,  6.3523e-02,  4.3915e-01,\n",
       "         2.1401e-01, -2.6069e-01, -3.1893e-02, -2.3265e-01,  1.6981e-02,\n",
       "        -5.4482e-01,  1.4991e-01, -4.0385e-02,  2.7873e-01, -2.7375e-01,\n",
       "        -1.7697e-01, -4.4448e-02, -1.5962e-01,  2.7987e-01, -3.1823e-01,\n",
       "         1.2173e-01,  8.7380e-02,  2.3677e-01,  3.7452e-01, -7.7311e-01,\n",
       "        -8.6525e-02,  1.2986e-01, -3.7762e-01, -1.0827e-01,  8.1266e-02],\n",
       "       grad_fn=<SliceBackward>)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grad[0][:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 1.0522e-01, -4.3441e-01,  6.8575e-02,  1.9317e-01,  2.3089e-01,\n",
       "         8.9383e-02,  4.8135e-01,  3.4231e-01, -2.8888e-02,  2.9547e-01,\n",
       "         2.8443e-01, -2.8834e-01, -3.3908e-01, -6.9788e-02, -2.1918e-01,\n",
       "        -8.6357e-02, -3.1047e-01, -2.9438e-01,  3.0658e-01, -2.4802e-01,\n",
       "         1.2108e-01, -6.8747e-02,  2.7700e-01,  7.4928e-01, -1.6137e-01,\n",
       "         1.9986e-01,  8.6020e-01, -3.2498e-03,  3.9949e-01, -6.5910e-03,\n",
       "         3.8083e-01,  9.6820e-02, -1.7064e-01, -4.6541e-01,  3.8144e-01,\n",
       "         4.1289e-01, -4.5711e-01,  1.2691e-01,  3.8861e-01,  2.4503e-01,\n",
       "         1.4239e-01,  1.1239e-01, -2.2420e-01, -1.4887e-01, -2.0484e-01,\n",
       "         8.3919e-04,  3.8844e-01, -1.0954e-01,  2.6535e-02,  1.7529e-01,\n",
       "         2.3041e-01,  3.5464e-01,  3.1174e-01, -1.2376e-01,  7.1551e-02,\n",
       "         1.5415e-01, -1.3680e-02, -2.2070e-01, -3.1524e-01, -1.0761e-01,\n",
       "         3.6819e-01, -3.7579e-01,  1.5527e-02, -8.0767e-02,  5.8959e-01,\n",
       "        -4.3346e-02, -3.5617e-01,  1.6644e-01,  8.3658e-01,  4.5370e-01,\n",
       "        -2.6807e-01, -5.2054e-01, -1.0200e-01, -1.4023e-01,  2.3669e-01,\n",
       "         4.4115e-01, -3.0876e-01, -1.7442e-02,  1.0991e-01,  5.2232e-01,\n",
       "        -7.2548e-01,  1.6468e-01, -3.6835e-01, -1.7887e-01,  4.8968e-02,\n",
       "        -3.5883e-01,  2.4995e-01,  5.3284e-02, -3.0779e-01,  9.3714e-03,\n",
       "         3.7273e-01,  1.8666e-01, -1.8925e-01, -7.4189e-02, -2.4598e-01,\n",
       "        -1.0307e-01,  1.6970e-01, -2.7702e-01, -2.3356e-01, -1.4469e-01],\n",
       "       grad_fn=<SliceBackward>)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grad[1][:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.2546,  0.2825,  0.2804,  1.0867,  0.7721,  0.3622, -0.5979, -0.5619,\n",
       "        -0.8070,  0.4958,  0.0262, -0.4871, -1.2632,  1.1464,  0.0784,  0.2070,\n",
       "        -0.2882, -1.5814, -0.5747,  0.4433,  0.8672,  1.2101,  0.9946, -2.5411,\n",
       "         1.3365, -0.6848, -0.3588,  0.1659,  0.6818, -0.1192, -0.0901,  1.2334,\n",
       "         2.8858, -1.4674, -2.0275,  0.6004, -1.4563,  0.0986, -0.1476, -0.2667,\n",
       "        -0.3497, -0.6536, -0.5182,  0.8500, -0.1064, -1.7516, -0.4474,  0.0311,\n",
       "         0.7674,  1.1715, -0.5634,  0.3112,  0.7803, -0.2004,  1.1978, -0.4738,\n",
       "        -0.2542, -1.3166,  0.0118, -2.2514,  0.6150, -2.2872,  0.3073,  0.9277,\n",
       "        -0.4295, -1.8750,  0.6777,  0.4519,  1.1443,  1.0001,  0.8119, -0.3817,\n",
       "         0.0789, -0.9182, -1.6049, -0.4204,  0.4300, -0.0655,  0.2086, -0.0031,\n",
       "         0.0825,  0.1779,  0.9970,  0.0059,  0.6481,  0.5044, -0.6111, -2.1053,\n",
       "         1.3982, -1.0493, -0.4526, -0.9328, -0.9673, -0.6060, -2.0955, -0.5374,\n",
       "        -0.9446, -1.2989,  0.3348,  0.3178], grad_fn=<SliceBackward>)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v2[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_copy = img_batch[0].clone().requires_grad_(True)\n",
    "output = layer(img_copy).squeeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "J_T_v2 = autograd.grad(v2.T @ output, img_copy, create_graph=True)[0].squeeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.0967,  0.6613,  0.0904, -0.5911, -0.2223,  0.0473,  0.2573, -0.5294,\n",
       "        -0.6959,  0.4946, -0.2523,  0.0323, -0.5638, -0.1927, -0.4454,  0.8830,\n",
       "        -0.0125,  0.2515, -0.5234, -0.2306, -0.1667,  0.2894, -0.6074, -1.1030,\n",
       "         0.2901, -0.0295, -0.0454,  0.2911,  0.3025, -0.1430, -0.4111,  0.0812,\n",
       "        -0.2916,  0.0162,  0.3134, -1.0102, -0.1975,  0.3630, -0.6655,  0.1572,\n",
       "         0.1311,  0.0599, -0.3220,  0.1571, -0.4180, -0.4647, -0.0366, -0.2610,\n",
       "        -0.2052,  0.6103,  0.8097, -0.3804,  0.5247, -0.7721,  0.3280,  0.5229,\n",
       "        -1.5179, -0.7838, -0.7823, -0.0840, -0.0044,  0.0189, -0.1848, -0.0462,\n",
       "        -0.0748,  0.5890,  0.9152,  0.0908, -0.1914, -0.2719, -0.0801, -0.0293,\n",
       "        -0.2030, -0.1667, -0.8302,  0.3030,  0.2898, -0.3585,  0.8013, -0.8045,\n",
       "         0.1601, -0.3660,  0.2089,  0.0887, -0.2815, -0.1210,  0.2246,  0.0129,\n",
       "        -0.1660,  0.0269,  0.1965,  0.4410,  0.4809,  0.4523,  0.2827,  0.2874,\n",
       "        -0.4194, -0.2391,  0.2770, -0.9252], grad_fn=<SliceBackward>)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "J_T_v2[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_copy = img_batch[28].clone().requires_grad_(True)\n",
    "output = layer(img_copy).squeeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "J_T_v2 = autograd.grad(v2.T @ output, img_copy, create_graph=True)[0].squeeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.0967,  0.6613,  0.0904, -0.5911, -0.2223,  0.0473,  0.2573, -0.5294,\n",
       "        -0.6959,  0.4946, -0.2523,  0.0323, -0.5638, -0.1927, -0.4454,  0.8830,\n",
       "        -0.0125,  0.2515, -0.5234, -0.2306, -0.1667,  0.2894, -0.6074, -1.1030,\n",
       "         0.2901, -0.0295, -0.0454,  0.2911,  0.3025, -0.1430, -0.4111,  0.0812,\n",
       "        -0.2916,  0.0162,  0.3134, -1.0102, -0.1975,  0.3630, -0.6655,  0.1572,\n",
       "         0.1311,  0.0599, -0.3220,  0.1571, -0.4180, -0.4647, -0.0366, -0.2610,\n",
       "        -0.2052,  0.6103,  0.8097, -0.3804,  0.5247, -0.7721,  0.3280,  0.5229,\n",
       "        -1.5179, -0.7838, -0.7823, -0.0840, -0.0044,  0.0189, -0.1848, -0.0462,\n",
       "        -0.0748,  0.5890,  0.9152,  0.0908, -0.1914, -0.2719, -0.0801, -0.0293,\n",
       "        -0.2030, -0.1667, -0.8302,  0.3030,  0.2898, -0.3585,  0.8013, -0.8045,\n",
       "         0.1601, -0.3660,  0.2089,  0.0887, -0.2815, -0.1210,  0.2246,  0.0129,\n",
       "        -0.1660,  0.0269,  0.1965,  0.4410,  0.4809,  0.4523,  0.2827,  0.2874,\n",
       "        -0.4194, -0.2391,  0.2770, -0.9252], grad_fn=<SliceBackward>)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "J_T_v2[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 0.4045,  0.7945,  0.6925,  ..., -0.9007, -0.6260, -0.2170],\n",
       "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         ...,\n",
       "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]]),)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_batch[0].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "it = iter(img_batch_copy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 14])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_batch.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "prod = output_batch @ v2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         ...,\n",
       "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         [ 0.0292,  0.6687, -0.5288,  ...,  1.2759, -0.4639,  0.0093],\n",
       "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
       "        grad_fn=<AsStridedBackward>),)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "autograd.grad(prod[i - 1], img_batch_copy, retain_graph=True, create_graph=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         ...,\n",
       "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         [ 0.0292,  0.6687, -0.5288,  ...,  1.2759, -0.4639,  0.0093]],\n",
       "        grad_fn=<AsStridedBackward>),)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "autograd.grad(prod[i], img_batch_copy, retain_graph=True, create_graph=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "grad = []\n",
    "for i in range(32):\n",
    "    grad.append(autograd.grad(prod[i], img_batch_copy, retain_graph=True, create_graph=True)[0][i])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([ 0.0292,  0.6687, -0.5288,  ...,  1.2759, -0.4639,  0.0093],\n",
       "        grad_fn=<SelectBackward>),\n",
       " tensor([ 0.0292,  0.6687, -0.5288,  ...,  1.2759, -0.4639,  0.0093],\n",
       "        grad_fn=<SelectBackward>),\n",
       " tensor([ 0.0292,  0.6687, -0.5288,  ...,  1.2759, -0.4639,  0.0093],\n",
       "        grad_fn=<SelectBackward>),\n",
       " tensor([ 0.0292,  0.6687, -0.5288,  ...,  1.2759, -0.4639,  0.0093],\n",
       "        grad_fn=<SelectBackward>),\n",
       " tensor([ 0.0292,  0.6687, -0.5288,  ...,  1.2759, -0.4639,  0.0093],\n",
       "        grad_fn=<SelectBackward>),\n",
       " tensor([ 0.0292,  0.6687, -0.5288,  ...,  1.2759, -0.4639,  0.0093],\n",
       "        grad_fn=<SelectBackward>),\n",
       " tensor([ 0.0292,  0.6687, -0.5288,  ...,  1.2759, -0.4639,  0.0093],\n",
       "        grad_fn=<SelectBackward>),\n",
       " tensor([ 0.0292,  0.6687, -0.5288,  ...,  1.2759, -0.4639,  0.0093],\n",
       "        grad_fn=<SelectBackward>),\n",
       " tensor([ 0.0292,  0.6687, -0.5288,  ...,  1.2759, -0.4639,  0.0093],\n",
       "        grad_fn=<SelectBackward>),\n",
       " tensor([ 0.0292,  0.6687, -0.5288,  ...,  1.2759, -0.4639,  0.0093],\n",
       "        grad_fn=<SelectBackward>),\n",
       " tensor([ 0.0292,  0.6687, -0.5288,  ...,  1.2759, -0.4639,  0.0093],\n",
       "        grad_fn=<SelectBackward>),\n",
       " tensor([ 0.0292,  0.6687, -0.5288,  ...,  1.2759, -0.4639,  0.0093],\n",
       "        grad_fn=<SelectBackward>),\n",
       " tensor([ 0.0292,  0.6687, -0.5288,  ...,  1.2759, -0.4639,  0.0093],\n",
       "        grad_fn=<SelectBackward>),\n",
       " tensor([ 0.0292,  0.6687, -0.5288,  ...,  1.2759, -0.4639,  0.0093],\n",
       "        grad_fn=<SelectBackward>),\n",
       " tensor([ 0.0292,  0.6687, -0.5288,  ...,  1.2759, -0.4639,  0.0093],\n",
       "        grad_fn=<SelectBackward>),\n",
       " tensor([ 0.0292,  0.6687, -0.5288,  ...,  1.2759, -0.4639,  0.0093],\n",
       "        grad_fn=<SelectBackward>),\n",
       " tensor([ 0.0292,  0.6687, -0.5288,  ...,  1.2759, -0.4639,  0.0093],\n",
       "        grad_fn=<SelectBackward>),\n",
       " tensor([ 0.0292,  0.6687, -0.5288,  ...,  1.2759, -0.4639,  0.0093],\n",
       "        grad_fn=<SelectBackward>),\n",
       " tensor([ 0.0292,  0.6687, -0.5288,  ...,  1.2759, -0.4639,  0.0093],\n",
       "        grad_fn=<SelectBackward>),\n",
       " tensor([ 0.0292,  0.6687, -0.5288,  ...,  1.2759, -0.4639,  0.0093],\n",
       "        grad_fn=<SelectBackward>),\n",
       " tensor([ 0.0292,  0.6687, -0.5288,  ...,  1.2759, -0.4639,  0.0093],\n",
       "        grad_fn=<SelectBackward>),\n",
       " tensor([ 0.0292,  0.6687, -0.5288,  ...,  1.2759, -0.4639,  0.0093],\n",
       "        grad_fn=<SelectBackward>),\n",
       " tensor([ 0.0292,  0.6687, -0.5288,  ...,  1.2759, -0.4639,  0.0093],\n",
       "        grad_fn=<SelectBackward>),\n",
       " tensor([ 0.0292,  0.6687, -0.5288,  ...,  1.2759, -0.4639,  0.0093],\n",
       "        grad_fn=<SelectBackward>),\n",
       " tensor([ 0.0292,  0.6687, -0.5288,  ...,  1.2759, -0.4639,  0.0093],\n",
       "        grad_fn=<SelectBackward>),\n",
       " tensor([ 0.0292,  0.6687, -0.5288,  ...,  1.2759, -0.4639,  0.0093],\n",
       "        grad_fn=<SelectBackward>),\n",
       " tensor([ 0.0292,  0.6687, -0.5288,  ...,  1.2759, -0.4639,  0.0093],\n",
       "        grad_fn=<SelectBackward>),\n",
       " tensor([ 0.0292,  0.6687, -0.5288,  ...,  1.2759, -0.4639,  0.0093],\n",
       "        grad_fn=<SelectBackward>),\n",
       " tensor([ 0.0292,  0.6687, -0.5288,  ...,  1.2759, -0.4639,  0.0093],\n",
       "        grad_fn=<SelectBackward>),\n",
       " tensor([ 0.0292,  0.6687, -0.5288,  ...,  1.2759, -0.4639,  0.0093],\n",
       "        grad_fn=<SelectBackward>),\n",
       " tensor([ 0.0292,  0.6687, -0.5288,  ...,  1.2759, -0.4639,  0.0093],\n",
       "        grad_fn=<SelectBackward>),\n",
       " tensor([ 0.0292,  0.6687, -0.5288,  ...,  1.2759, -0.4639,  0.0093],\n",
       "        grad_fn=<SelectBackward>)]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.7696, -1.3836,  1.5466,  ..., -0.4911, -1.9428,  1.3286],\n",
       "        [-1.7435,  0.1724,  0.4237,  ..., -0.1114,  0.7424, -1.0351],\n",
       "        [-0.7715, -0.7562,  0.1746,  ..., -0.1764, -0.4345, -0.0455],\n",
       "        ...,\n",
       "        [ 1.1638, -0.1136, -0.0086,  ...,  0.9239,  0.9385,  0.6597],\n",
       "        [ 0.8228, -0.3939, -0.7540,  ..., -1.3014, -0.2386, -0.7362],\n",
       "        [ 1.5424, -0.5956,  0.4882,  ...,  1.3647,  0.3631, -0.4734]],\n",
       "       requires_grad=True)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_batch_copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         ...,\n",
       "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         [-0.0777, -0.6286, -0.6025,  ...,  0.4405,  0.5199,  0.1628]],\n",
       "        grad_fn=<AsStridedBackward>),)"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "autograd.grad(prod[i], img_batch_copy, create_graph=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "grad can be implicitly created only for scalar outputs",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-84-1fc3a614b085>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mfull_grad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg_batch_copy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/NLP/lib/python3.6/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mgrad\u001b[0;34m(outputs, inputs, grad_outputs, retain_graph, create_graph, only_inputs, allow_unused)\u001b[0m\n\u001b[1;32m    141\u001b[0m         \u001b[0mgrad_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrad_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 143\u001b[0;31m     \u001b[0mgrad_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_make_grads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    144\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mretain_graph\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    145\u001b[0m         \u001b[0mretain_graph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/NLP/lib/python3.6/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36m_make_grads\u001b[0;34m(outputs, grads)\u001b[0m\n\u001b[1;32m     26\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequires_grad\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m                     \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"grad can be implicitly created only for scalar outputs\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m                 \u001b[0mnew_grads\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mones_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: grad can be implicitly created only for scalar outputs"
     ]
    }
   ],
   "source": [
    "full_grad = autograd.grad(prod, img_batch_copy, retain_graph=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "J_T_v2 = img_batch_copy.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 12288])"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_batch_copy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = J_T_v2 @ v1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([75069.2734, 75069.2734, 75069.2734, 75069.2734, 75069.2734, 75069.2734,\n",
       "        75069.2734, 75069.2734, 75069.2734, 75069.2734, 75069.2734, 75069.2734,\n",
       "        75069.2734, 75069.2734, 75069.2734, 75069.2734, 75069.2734, 75069.2734,\n",
       "        75069.2734, 75069.2734, 75069.2734, 75069.2734, 75069.2734, 75069.2734,\n",
       "        75069.2734, 75069.2734, 75069.2734, 75069.2734, 75069.2734, 75069.2734,\n",
       "        75069.2734, 75069.2734], grad_fn=<MvBackward>)"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Tensor' object has no attribute 'zero_grad'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-111-a9b1b74d8506>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Tensor' object has no attribute 'zero_grad'"
     ]
    }
   ],
   "source": [
    "v2.grad.zero_()\n",
    "v2.data.zero_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[ 5.0238e-01, -4.1303e-01,  5.7906e-01,  ..., -1.3733e+00,\n",
       "           -1.7838e+00,  1.8186e+00],\n",
       "          [-1.1135e-01, -7.8527e-01, -4.3307e-01,  ...,  1.2721e+00,\n",
       "           -3.2110e-01,  1.2528e-01],\n",
       "          [-1.1080e+00, -1.1124e+00, -8.9090e-01,  ...,  1.8135e+00,\n",
       "           -1.3762e+00, -3.5865e-01],\n",
       "          ...,\n",
       "          [-1.3235e-01,  1.9272e-01,  1.3293e+00,  ...,  1.0934e+00,\n",
       "            1.0545e+00, -5.4225e-01],\n",
       "          [-7.8190e-01, -1.1393e+00, -1.5905e+00,  ...,  1.5941e+00,\n",
       "           -6.1499e-01,  6.3828e-02],\n",
       "          [-3.6597e-01, -1.8701e+00,  1.7525e-01,  ..., -1.2583e+00,\n",
       "           -1.2127e-01,  3.9368e-03]],\n",
       "\n",
       "         [[-8.0723e-01, -3.4776e-01,  5.8503e-01,  ..., -8.9609e-01,\n",
       "            7.6539e-01,  5.5952e-01],\n",
       "          [-3.2787e-02,  1.6630e+00, -3.0340e-01,  ...,  5.6782e-01,\n",
       "            6.1339e-01,  4.0386e-01],\n",
       "          [-7.1178e-01, -1.6168e+00, -4.8105e-01,  ..., -1.9892e+00,\n",
       "           -5.6242e-01,  2.8317e-01],\n",
       "          ...,\n",
       "          [ 1.3292e+00,  1.1332e+00, -3.7908e-01,  ..., -9.0894e-01,\n",
       "            1.8476e-01, -2.6974e-01],\n",
       "          [-5.8321e-02, -1.1734e+00, -3.5334e-01,  ..., -1.0883e+00,\n",
       "            1.2059e+00,  9.7670e-01],\n",
       "          [-2.1061e+00, -1.3041e+00,  1.7725e-02,  ..., -1.0518e-01,\n",
       "           -3.8289e-01, -3.1170e-01]],\n",
       "\n",
       "         [[ 6.8411e-01, -5.1341e-01,  5.4546e-03,  ...,  5.8196e-01,\n",
       "            5.4999e-01,  6.3752e-02],\n",
       "          [ 7.7581e-01,  4.1358e-01, -1.2155e+00,  ...,  6.2093e-01,\n",
       "           -1.5330e-01,  7.1624e-01],\n",
       "          [-2.0171e+00,  3.2569e-01, -1.2436e+00,  ..., -6.0440e-01,\n",
       "           -5.4314e-01,  2.0602e-01],\n",
       "          ...,\n",
       "          [ 5.9740e-03, -1.3980e+00, -1.0678e+00,  ..., -2.5494e-01,\n",
       "            1.8121e-01, -1.2822e-01],\n",
       "          [ 8.4800e-01,  3.7869e-01, -8.2979e-01,  ...,  2.1583e+00,\n",
       "            1.4804e+00, -2.0636e-01],\n",
       "          [ 1.5923e+00,  1.0153e+00, -6.0581e-01,  ..., -5.1030e-01,\n",
       "            8.1011e-01, -7.7631e-01]]],\n",
       "\n",
       "\n",
       "        [[[-1.7066e-01, -2.4193e-01,  3.8870e-01,  ...,  8.0442e-02,\n",
       "           -1.4769e+00, -7.0521e-01],\n",
       "          [-1.1828e-02,  2.0480e+00,  1.4033e+00,  ..., -1.4246e+00,\n",
       "            6.3205e-02,  8.2370e-01],\n",
       "          [-6.9029e-01, -3.0759e-01, -1.0211e+00,  ..., -4.8600e-01,\n",
       "           -1.9771e-02,  8.8440e-02],\n",
       "          ...,\n",
       "          [ 1.3274e+00,  3.4973e-02, -6.3432e-01,  ..., -5.0547e-02,\n",
       "            1.0308e+00, -2.4176e-01],\n",
       "          [-1.3234e-01, -3.2086e-01, -4.4323e-02,  ..., -1.0366e+00,\n",
       "            1.0454e+00, -5.3497e-01],\n",
       "          [ 9.9176e-01,  2.1046e-01,  3.3859e-01,  ...,  1.2316e+00,\n",
       "            1.7056e+00,  4.6084e-01]],\n",
       "\n",
       "         [[-1.2705e-01, -3.2066e-01,  3.1470e-02,  ...,  1.6349e+00,\n",
       "            1.9693e-01,  7.8732e-01],\n",
       "          [-6.6370e-01,  2.0952e+00, -8.7675e-03,  ..., -1.9256e-01,\n",
       "           -4.4895e-01, -6.9570e-02],\n",
       "          [-1.8792e+00,  7.8181e-01,  5.3402e-01,  ...,  7.4398e-02,\n",
       "           -2.9868e-02,  7.0013e-01],\n",
       "          ...,\n",
       "          [-5.3195e-02,  1.4533e+00, -7.5757e-01,  ..., -1.7493e+00,\n",
       "           -9.5099e-01,  6.2826e-02],\n",
       "          [-1.1340e-01,  6.9732e-01, -1.6520e+00,  ..., -4.3854e-01,\n",
       "           -6.4062e-01,  1.1227e+00],\n",
       "          [-9.0524e-01,  1.8456e+00, -2.3295e+00,  ..., -1.0462e+00,\n",
       "            2.0838e+00, -2.0334e+00]],\n",
       "\n",
       "         [[-2.2834e-02,  6.0887e-01,  4.8328e-01,  ...,  6.8179e-01,\n",
       "            8.3881e-01,  6.8979e-01],\n",
       "          [-5.5056e-01,  9.1825e-01,  6.0260e-01,  ...,  9.4814e-01,\n",
       "           -2.4751e+00,  5.2315e-02],\n",
       "          [-2.7641e-01,  1.4323e+00,  8.6298e-01,  ...,  3.8402e-01,\n",
       "            3.0255e-01,  1.7408e+00],\n",
       "          ...,\n",
       "          [ 1.7852e+00,  1.0314e+00, -1.1514e+00,  ..., -7.6760e-01,\n",
       "            2.4341e+00,  1.2455e+00],\n",
       "          [-6.1330e-02,  1.3157e-01,  2.7333e-01,  ..., -1.0426e+00,\n",
       "            1.5383e+00, -1.3726e+00],\n",
       "          [-7.8354e-01, -1.9056e+00, -3.8772e+00,  ...,  1.2745e+00,\n",
       "            9.5349e-01,  1.1640e+00]]],\n",
       "\n",
       "\n",
       "        [[[ 6.6249e-01, -4.3076e-01, -2.9461e+00,  ..., -1.4401e+00,\n",
       "            1.6353e-01,  2.1695e-01],\n",
       "          [-1.0160e+00,  7.6101e-01,  2.6896e+00,  ..., -3.2293e-01,\n",
       "           -1.6312e+00,  1.6699e+00],\n",
       "          [ 7.6582e-01,  9.8109e-01, -1.3656e-01,  ...,  1.7200e+00,\n",
       "           -7.5499e-01,  1.4728e+00],\n",
       "          ...,\n",
       "          [ 1.0955e+00,  1.8640e-01, -7.9388e-01,  ...,  3.2209e-01,\n",
       "            1.8421e+00, -3.3657e-01],\n",
       "          [ 1.8067e+00, -3.3077e-01,  1.7959e+00,  ..., -2.8224e-01,\n",
       "            1.6408e+00, -5.4922e-01],\n",
       "          [-1.5287e-01, -1.2497e+00,  1.8555e+00,  ...,  4.7202e-01,\n",
       "           -1.9967e+00,  8.2484e-01]],\n",
       "\n",
       "         [[ 8.3234e-01, -3.8804e-01,  8.2293e-01,  ..., -9.2721e-01,\n",
       "           -9.4898e-01,  1.4828e+00],\n",
       "          [ 1.2797e+00,  3.6498e-01, -2.8185e+00,  ..., -6.8988e-01,\n",
       "            5.5978e-01, -9.5091e-01],\n",
       "          [ 7.7338e-01,  1.6234e+00,  1.2483e+00,  ..., -4.3226e-01,\n",
       "            2.4619e-01, -1.6273e-01],\n",
       "          ...,\n",
       "          [ 1.3776e+00,  3.8118e-01, -1.8746e-01,  ...,  3.5325e-01,\n",
       "           -8.2678e-02,  2.4885e+00],\n",
       "          [ 6.7897e-01, -8.3159e-01,  6.9920e-01,  ...,  5.3149e-01,\n",
       "           -1.3170e+00,  1.2002e-01],\n",
       "          [-4.7224e-01, -1.3613e-01,  1.9678e+00,  ...,  1.8226e+00,\n",
       "            8.8862e-01, -8.8136e-01]],\n",
       "\n",
       "         [[-1.0359e-01, -7.5030e-01,  8.8077e-01,  ..., -1.9435e+00,\n",
       "           -1.5381e-02,  5.7600e-01],\n",
       "          [-9.4275e-01, -3.0686e-01, -3.3883e-01,  ...,  3.4452e-01,\n",
       "           -8.3364e-01,  8.0253e-01],\n",
       "          [ 3.0813e-01, -1.3642e+00, -1.0117e+00,  ..., -8.0432e-01,\n",
       "            5.5955e-01,  1.3170e+00],\n",
       "          ...,\n",
       "          [-3.3804e-01, -8.4864e-01, -1.6276e+00,  ..., -4.0211e-01,\n",
       "            8.8021e-01,  1.2253e+00],\n",
       "          [-1.0870e+00, -1.1629e+00, -5.8996e-01,  ...,  1.8696e+00,\n",
       "           -6.3188e-01, -7.7325e-01],\n",
       "          [ 6.5939e-01, -2.3137e-01, -1.6654e+00,  ..., -7.4587e-01,\n",
       "            5.8991e-02, -2.6727e-01]]],\n",
       "\n",
       "\n",
       "        ...,\n",
       "\n",
       "\n",
       "        [[[-8.8848e-01,  1.5939e+00, -1.1131e-01,  ..., -1.0980e+00,\n",
       "            8.9662e-01,  8.1624e-01],\n",
       "          [ 2.1141e+00, -5.5732e-01, -1.6774e-01,  ..., -3.4241e-01,\n",
       "           -6.8527e-01, -3.2619e-03],\n",
       "          [ 6.7569e-01, -3.8796e-01, -8.3047e-01,  ..., -1.0707e+00,\n",
       "            1.7594e-01,  5.8428e-02],\n",
       "          ...,\n",
       "          [ 3.9819e-02,  2.9009e-01, -4.3806e-02,  ...,  3.1947e+00,\n",
       "           -5.6702e-01,  6.2084e-01],\n",
       "          [-5.6253e-01,  9.6230e-01, -1.0909e+00,  ...,  3.0368e+00,\n",
       "           -6.7568e-01, -2.0082e+00],\n",
       "          [-1.4886e-01, -5.0427e-01, -8.9279e-02,  ..., -1.1628e+00,\n",
       "           -3.2118e-01, -4.8714e-01]],\n",
       "\n",
       "         [[-4.5745e-01,  8.1481e-01,  1.6163e+00,  ..., -1.4410e+00,\n",
       "           -5.6314e-01, -5.2824e-01],\n",
       "          [ 1.2586e+00, -2.4945e+00,  4.4132e-01,  ...,  4.5679e-01,\n",
       "           -1.4400e-01, -4.9434e-01],\n",
       "          [ 9.8022e-01, -1.8531e-01, -1.9885e+00,  ..., -2.2594e-01,\n",
       "           -7.0609e-01, -1.1843e-01],\n",
       "          ...,\n",
       "          [ 1.4154e+00,  7.1648e-01,  1.5874e+00,  ..., -1.1443e+00,\n",
       "           -9.0789e-01,  7.0050e-01],\n",
       "          [-1.0999e+00, -2.3713e-01,  1.1688e+00,  ...,  3.1694e-01,\n",
       "            6.8502e-01, -8.8641e-01],\n",
       "          [-1.3734e+00, -7.0639e-01, -6.3516e-01,  ..., -8.5444e-01,\n",
       "           -1.7074e+00,  1.2146e-01]],\n",
       "\n",
       "         [[ 1.4325e-01, -4.3991e-01, -3.8111e-01,  ..., -3.1994e-01,\n",
       "            3.4737e-01, -5.2383e-01],\n",
       "          [-8.0217e-01,  2.7717e-01, -9.5033e-01,  ..., -2.1644e-01,\n",
       "            7.0578e-01, -3.0715e-02],\n",
       "          [ 7.5746e-01, -1.3708e+00,  2.5950e-01,  ...,  2.3382e-01,\n",
       "            9.4882e-01,  1.0423e+00],\n",
       "          ...,\n",
       "          [ 5.2040e-01,  7.5576e-01,  3.7565e-01,  ...,  1.8534e+00,\n",
       "           -3.9566e-02, -4.9035e-01],\n",
       "          [ 9.0874e-01, -2.1289e+00,  2.5384e+00,  ..., -7.8129e-01,\n",
       "            8.5535e-01, -1.7443e-01],\n",
       "          [ 5.8078e-01, -1.1265e+00,  1.9532e+00,  ..., -1.6382e+00,\n",
       "           -1.5151e+00, -2.4627e+00]]],\n",
       "\n",
       "\n",
       "        [[[-2.0096e+00, -1.7526e+00, -7.4905e-02,  ..., -8.2557e-01,\n",
       "           -7.2088e-01, -3.7227e-02],\n",
       "          [-4.1615e-01,  4.2450e-01, -1.5237e+00,  ..., -3.1604e-01,\n",
       "            1.7042e-01, -8.9652e-01],\n",
       "          [-1.4988e+00, -1.8861e+00, -5.9289e-01,  ...,  1.7096e+00,\n",
       "           -2.5608e+00,  2.1592e+00],\n",
       "          ...,\n",
       "          [-3.4415e-01,  1.1415e+00,  2.8882e-01,  ...,  1.4068e+00,\n",
       "           -2.5321e-01, -1.7212e+00],\n",
       "          [-2.6386e+00,  5.2813e-01, -1.3419e+00,  ..., -1.7866e-01,\n",
       "           -7.0825e-01, -1.0953e+00],\n",
       "          [-1.2565e+00,  1.4684e+00,  2.3076e+00,  ...,  1.8049e+00,\n",
       "            6.7105e-02,  1.6670e+00]],\n",
       "\n",
       "         [[-6.7057e-01,  1.6476e+00,  6.5344e-01,  ...,  7.4212e-01,\n",
       "           -1.1469e+00, -2.9389e-01],\n",
       "          [-9.1879e-01, -1.0326e+00, -1.3055e+00,  ...,  7.4732e-01,\n",
       "            7.2236e-01,  1.0067e+00],\n",
       "          [ 1.5272e+00, -6.4644e-01, -1.0438e+00,  ..., -9.8220e-01,\n",
       "            5.8505e-01,  1.9337e+00],\n",
       "          ...,\n",
       "          [ 9.0983e-02, -8.7773e-01, -5.6265e-02,  ...,  1.1597e+00,\n",
       "           -2.5521e+00,  7.2017e-01],\n",
       "          [ 4.3733e-01, -1.5993e-02, -1.3138e+00,  ...,  9.0778e-01,\n",
       "           -1.6981e+00, -3.7356e-01],\n",
       "          [-1.0699e+00,  4.2428e-01,  7.9847e-01,  ...,  2.7942e-01,\n",
       "            1.9344e+00, -5.3792e-02]],\n",
       "\n",
       "         [[ 7.6870e-01, -1.2798e+00, -6.4659e-01,  ...,  7.5028e-02,\n",
       "            3.1862e-01, -1.4767e+00],\n",
       "          [ 5.3544e-01,  4.3113e-01, -3.5091e-01,  ..., -2.0227e+00,\n",
       "           -1.4451e+00, -2.9612e-01],\n",
       "          [-1.6131e+00, -7.8115e-01, -3.1334e-01,  ..., -2.2768e-01,\n",
       "            8.6276e-01,  8.9279e-02],\n",
       "          ...,\n",
       "          [-1.1677e-01,  1.0152e+00,  1.3097e+00,  ..., -8.8842e-01,\n",
       "           -2.9889e-01, -7.5054e-01],\n",
       "          [ 1.4129e+00, -9.2633e-01, -2.6242e-02,  ...,  8.1576e-01,\n",
       "            6.5477e-01,  1.2818e+00],\n",
       "          [-7.6130e-01, -9.7757e-02, -6.4225e-01,  ...,  7.0494e-02,\n",
       "           -1.6916e+00, -3.9064e-01]]],\n",
       "\n",
       "\n",
       "        [[[ 1.5870e+00, -7.7100e-02,  5.1034e-01,  ...,  1.1891e-01,\n",
       "            6.7338e-01,  7.4915e-01],\n",
       "          [ 1.6143e-01,  4.1894e-01, -9.8825e-02,  ...,  2.6741e+00,\n",
       "           -1.5337e+00,  1.5600e-01],\n",
       "          [-6.6902e-01,  5.6100e-01,  1.7527e+00,  ...,  1.1468e+00,\n",
       "           -4.2521e-01, -1.0781e+00],\n",
       "          ...,\n",
       "          [ 1.6101e-01,  1.9852e-01, -1.6172e+00,  ...,  1.0164e+00,\n",
       "            1.0787e+00,  4.1606e-01],\n",
       "          [ 7.0209e-01, -2.0388e-01, -1.2853e+00,  ...,  6.1371e-01,\n",
       "            6.0586e-01, -4.9720e-01],\n",
       "          [-1.8382e+00,  1.1101e+00, -2.3898e-01,  ..., -8.5107e-02,\n",
       "            1.4277e+00,  2.7762e-01]],\n",
       "\n",
       "         [[ 2.5493e-01, -1.1719e+00, -1.3868e+00,  ...,  4.5273e-01,\n",
       "            5.1150e-01, -1.7050e+00],\n",
       "          [ 7.8285e-01,  6.8511e-01,  1.1528e+00,  ..., -1.2108e-01,\n",
       "           -5.5012e-01,  1.2005e-01],\n",
       "          [ 5.5751e-02, -9.1793e-01, -1.0977e+00,  ..., -1.1944e+00,\n",
       "           -7.6168e-01, -7.6145e-01],\n",
       "          ...,\n",
       "          [ 6.6187e-01, -1.3485e-01,  9.6001e-01,  ..., -7.8014e-01,\n",
       "            1.0751e+00,  7.1432e-01],\n",
       "          [ 1.2343e+00, -3.7458e-01, -9.7343e-01,  ..., -4.9318e-01,\n",
       "            2.6314e-01,  2.3663e-01],\n",
       "          [-3.1542e-01,  8.4651e-02,  3.4930e-01,  ...,  3.8322e-01,\n",
       "            1.0237e+00, -2.3264e+00]],\n",
       "\n",
       "         [[-1.2695e+00, -5.1672e-01, -2.3302e-01,  ...,  1.1587e-01,\n",
       "           -9.9685e-01, -5.8934e-01],\n",
       "          [-1.5966e+00,  7.1380e-01,  5.6897e-01,  ...,  2.8635e-01,\n",
       "            9.0394e-01,  6.4875e-01],\n",
       "          [ 4.0052e-01, -2.6869e-01, -1.8943e+00,  ..., -2.8973e-02,\n",
       "            9.4223e-03,  1.6491e-01],\n",
       "          ...,\n",
       "          [ 1.3452e+00, -6.3218e-01,  1.7224e+00,  ..., -6.5550e-01,\n",
       "           -1.9609e+00, -9.5827e-01],\n",
       "          [-4.0414e-02, -6.9776e-01,  2.8806e+00,  ...,  1.5901e+00,\n",
       "           -8.9761e-01,  9.6663e-01],\n",
       "          [-2.2356e-01,  8.2589e-02, -1.7750e+00,  ...,  6.5525e-01,\n",
       "           -1.6618e+00,  5.0604e-01]]]], device='cuda:0')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float32"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.zeros_like(img_batch_copy).dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.device"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(next(model.parameters()).device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "print(next(layer.parameters()).device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
